---
title: "Statistique Bayésienne"
author: "Haeji Yun"
date: "2023-07-27"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---


```{r, echo = F, warning = F, message = F}
library(stringr)
library(ggplot2)
require(MCMCpack, quietly = T)
library(BMS)
library(psych)
library(dplyr)
library(forcats)
library(fastDummies)
library(gridExtra)
library(grid())
```


Dans cette étude, nous nous intéressons au nombre de points nécessaires pour obtenir une mutation professionnelle dans les lycées de l'académie de Versailles en 2012. Nous cherchons à expliquer ces points en nous basant sur les différents caratéristiques de lycée tels que l'effectif dans différentes séries, le taux de réussite, le taux d'accès etc.

Notre jeu de données contient 516 observations et 23 variables. Les observations correspondent aux couples établissement - discipline et les variables correspondent à différentes caractéristiques de lycées. Nous considérons uniquement les filières du lycée général.

# 0. Chargement de données

Notre variable d'intérêt est la variable quantitative *Barre* qui correspond au nombre de points. 

Nous avons 5 covariables qualitatives qui sont :  
- Le code et le nom d'établissement  
- Le code et le nom de ville  
- La matière

Les autres 17 covariables quantitatives correspondent à différentes caractéristiques :  
- les effectifs dans les différentes series  
- les taux de résussite brut et attendu de chaque série  
- les taux d'accès brut et attendu en seconde  
- les taux d'accès brut et attendu en première  
- les taux de réussite totaux d'accès brut et attendu  
  
  
```{r, echo = F}
mutation = read.table('mutations2.csv', sep = ',', header = T)
colnames(mutation)
```




# 1. Etude Exploratoire

## Aperçu

À part les variables qualitatives qui donnent l'information sur l'identification du lycée et la discipline, le jeu de données comporte principalement des données quantitatives. Elles sont exprimées en nombre d'élèves pour les effectifs et en pourcentage pour les taux.

Nous observons une grande variabilité des effectifs globaux dans toutes les series avec leurs valeurs maximales 20 fois plus grandes de leurs valeurs minimales. Nous pouvons supposer qu'il y a une différence de taille entre les lycées.

Nous remarquons une légère variabilité de taux de réussite entre les différentes séries. Cette variabilité est presque inexistante pour les taux attendus.

Il y a également une  grande variabilité dans la variable *Barre*. Avec un grand écart entre les 3ème et 4ème quartiles, nous pouvons supposer qu'il y a quelques valeurs particulièrement élevées par rapport au reste.

```{r, echo = F, message = F}
mutation[,6:23] %>%
  select(where(is.numeric)) %>%
  psych::describe(quant = c(.25, .75)) %>%
  as_tibble(rownames = "rowname") %>%
  select(var=rowname, min, q25=Q0.25, median, q75=Q0.75, max, mean, sd)
```

Dans notre jeu de données, nous n'avons pas de données manquantes mais il existe 6 doublons. En supprimant les doublons, nous nous retrouvons avec 510 observations et toujours 23 variables.

```{r, echo = F}
mutation[(duplicated(mutation) | duplicated(mutation, fromLast = TRUE) | duplicated(mutation, fromLast = FALSE)),c(1,2,4,5)]
muatation = mutation[duplicated(mutation)==F,]
```






## Variables explicatives

**Variables quantitatives**

Nous pouvons étudier la corrélation des variables quantitatives avec une matrice de corrélation. Nous observons des corrélations sur des blocs de variables : 

- Le bloc des effectifs : l'effectif de seconde, l'effectif de primière, l'effectif de série L, l'effectif de série ES, et l'esffectif de serie S sont corréelés.

- Le bloc des taux : le taux brut de réussite de série S, le taux de réussite attendu de série L, le taux de réusssite attendu de série ES, le taux de réussite attendu de séries S, le taux d'accès brut de seconde, le taux d'accès attendu de seconde, le taux d'accès brut de première, le taux d'accès attendu de première,  le taux brut de résussite total, et le taux réussite total sont corrélés.

```{r, echo = F, message = F, fig.width = 12, fig.height = 11, fig.align = 'center'}
library(corrplot)
corrplot(cor(mutation[,6:23]), tl.col = "gray35")
```

\newpage
**Variables qualitatives**

Parmi les variables qualitatives, le code d'établissement, la ville, l'établissement, et la commune donnent l'information sur l'identité de l'établissement. Nous ne les utiliseront pas comme des covariables.

Pour chaque établissemnt, nous avons mêmes valeurs pour les variables explicatives quantitatives quelques soit la matière. Donc la matière semble clé parmi les variables qualitatives. Néanmoins, nous avons 36 matières différentes avec des matières qui sont très peu observées. 

Par exemple, nous avons les matières *G.IND.BOIS*, *G.ELECTRON*, et *ESTH.COSME* qui sont observées une fois. Les matières *NRC*, *ITALIEN*, *G.ELECTROT*, et *ARTSPLAST* sont observées deux fois dans tout le jeu de données. 

```{r, fig.align = 'center', fig.width = 12, echo = F, fig.height= 6}
ggplot(mutation, aes(fct_infreq(Matiere)))+
  geom_bar(fill = 'darkgoldenrod2')+
  theme_minimal()+
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 90))+
  ylab("Nombre d'observations")+
  xlab("Matière")+
  ggtitle("Distribution de Matière")
```

Puisque les variables très peu observées n'apportent pas d'information de qualité, nous allons supprimer les variables qui ont moins de 3 observations.

De plus, nous avons des matières qui n'apartiennent pas aux filières du lycée générale. Nous allons également les supprimer car nous nous intéressons qu'aux lycées générales.

Nous nous retrouvons donc avec 427 observations et 20 matières différentes.

Néanmoins, nous remarquons que le regroupement des matières est différent selon les lycées. Bien qu'il y a des lycées qui consière les matières uniques, il y a des lycées qui regroupe plusieurs matières dans un groupe pour leur attribuer un point de mutation unique au groupe.

- Il y a 9 lycées qui regroupent les *MATHS*, *S.V.T*, et *PHY.CHIMIE* en un seul groupe de *MATH.SC.PH*.

- Il y a 13 lycées qui regroupent les *HIST.GEO*, *LET MODERN*, *LETT CLASS* en un groupe de *LET.HIS.GE*.

- Il y a 8 lycées qui regroupent les *ANGLAIS*, *LET MODERN*, *LETT CLASS* en un groupe de *LET ANGLAI*.

- Il y a 4 lycées qui regroupent les *ESPAGNOL*, *LET MODERN*, *LETT CLASS* en un groupe de *LET ESPAGN*. 

```{r, echo = F}
tech_pro = c("ECO.GE.FIN", "ECO.GE.MK", "ECO.GE.COM", "SII.ING.ME", "BIOCH.BIOL", "ECO.GE.VEN", "SII.EE", "BIOTECHNOL", "ECO.GE.CPT", "SII.SIN", "SII.SIN", "G.ELECTROT", "NRC", "ESTH.COSME", "G.ELECTRON", "G.IND.BOIS","ITALIEN","ARTS PLAST")

mutation_gen = mutation[!(mutation$Matiere %in% tech_pro), ]

sort(table(mutation_gen$Matiere), decreasing = T)
```

Pour éviter que les mêmes matières soient considérées différentes, nous allons harmoniser le regroupement des maitères. Pour la simplicité, nous allons nous baser seulement sur la distribution de *Barre* de chaque regroupement pour l'harmonisation.

```{r, include = F}
mutation[mutation$Matiere %in% c("MATH.SC.PH", "MATHS", "S. V. T.", "PHY.CHIMIE"), c('ville','etablissement','Matiere', 'Barre')]%>%
  group_by(Matiere)%>%
  summarise(min = min(Barre), "Q-25" = quantile(Barre, 0.25), "Q-50" = quantile(Barre, 0.5), "Q-75" = quantile(Barre, 0.74), max = max(Barre))
```

Tout d'abord pour les matières scientifiques, il est difficile d'affecter le regroupement *MATH.SC.PH* à une des maitères *MATHS*, *S.V.T*, ou *PHY.CHIMIE* car nous n'observons pas de similitude particulière avec une des matières. Nous allons garder le regroupement tel qu'il est.

```{r, echo = F, fig.align = 'center', fig.width = 12, fig.height = 5.5}
ggplot(mutation[mutation$Matiere %in% c("MATH.SC.PH", "MATHS", "S. V. T.", "PHY.CHIMIE"), c('Matiere', 'Barre')], aes(Matiere, Barre))+
  geom_boxplot(col = 'darkgoldenrod3')+
  theme_minimal()+
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 90))+
  ylab("Barre")+
  xlab("Matière")+
  ggtitle("Distribution de Matière Scientifique")
```

Pour les matières littéraires, nous allons affecter les matières regroupées à une seule matière qui leur ressemble le plus en terme de distribution de *Barre* : 

- Nous allons remplacer le groupe *LET.HIS.GE* par la matière *HIST.GEO*.

- La maitère *ANGLAIS* remplace le groupe *LET ANGLAI*.

- La maitère *ESPAGNOL* remplace le groupe *LET ESPAGN*.

```{r, echo = F}
mutation[mutation$Matiere %in% c("LET.HIS.GE", "HIST. GEO.", "LET MODERN", "LETT CLASS", "LET ANGLAI", "LET ESPAGN", "ANGLAIS"), c('ville','etablissement','Matiere', 'Barre')]%>%
  group_by(Matiere)%>%
  summarise(min = min(Barre), "q-25" = quantile(Barre, 0.25), "q-50" = quantile(Barre, 0.5), "q-75" = quantile(Barre, 0.74), max = max(Barre))%>%
  arrange(min)
```


Au final, nous avons 15 matières avec 423 observations.

```{r, fig.align = 'center', fig.width = 12, echo = F, fig.height = 6}
mutation_gen[mutation_gen$Matiere == "LET ANGLAI", "Matiere"] = "ANGLAIS"
mutation_gen[mutation_gen$Matiere == "LET ESPAGN", "Matiere"] = "ESPAGNOL"
mutation_gen[mutation_gen$Matiere == "LET.HIS.GE", "Matiere"] = "HIST. GEO."

ggplot(mutation_gen, aes(fct_infreq(Matiere)))+
  geom_bar(fill = 'darkgoldenrod2')+
  theme_minimal()+
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 90))+
  ylab("Nombre d'observations")+
  xlab("Matière")+
  ggtitle("Distribution de Matière")
```

## Variable cible

Notre variable d'intérêt est *Barre*.

Nous avons une distribution avec longue queue à droit. Il y a beaucoup d'observations avec les valeurs entre 50 et 250. La plupart des observations se trouvent en dessus de 500 et nous avons quelques observations jusqu'à l'entour de 2100.

```{r, echo = F, fig.align = 'center', fig.width = 12, fig.height = 6}
barre = data.frame(barre = mutation$Barre)

ggplot(barre, aes(barre))+
  geom_histogram(bins = 20, fill = 'darkgoldenrod2')+
  theme_minimal()+
  theme(plot.title = element_text(hjust = 0.5))+
  ylab("Nombre d'observations")+
  xlab("Points")+
  ggtitle("Distribution de points nécessaires pour obtenir une mutation")
```

# 2. Régression Linéaire Bayésienne

```{r, echo = F}
mutation_gen = mutation_gen[,c(6,1:5,7:23)]
mutation_train = subset(mutation_gen, select = -c(code_etablissement, ville, etablissement, commune))

set.seed(13)
split = sample(2, nrow(mutation_train), replace = T, prob = c(0.9, 0.1))
train = mutation_train[split == 1, ]
test = mutation_train[split == 2, ]
```

Dans un premier temps, nous pouvons appliquer la régression bayésienne sur tout notre jeu de données avec 10.000 itérations. En utilisant la fonction MCMCRegress, nous pouvons obtenir un échantillon simulé à partir de la distribution posterior du modèle régression linéaire guassien en utilisant Gibbs sampling, une méthode d'une chaîne de Markov.

Nous avons pas mal de variables explicatives avec des quantiles qui contiennent le 0. En effet, la présence de 0 entre les quantiles 2,5% et 97,5% signifie qu'il y a une grande probabilité que le coefficient de ces variables peuvent être nul. Donc nous préférons d'exclure telles covariables que de l'inclure à tort dans le modèle.

Les variables qui ne contiennent pas de 0 dans les quantiles 2,5% - 97,5% sont les matières *anglais*, *doc lycées*, *éducation*, *espangol*, *histo & géo*, *lettres classiques*, *math & science & physique*, *maths*, *physique & chimie*, et *économie sociale*.

Le modèle considère que les variables matières comme significatives.

```{r, echo = F, warning = F}
reg = MCMCregress(Barre ~ ., data = train, b0 = 516)
print(summary(reg)[2], digits = 2)
```

\newpage
Pour chaque variable, nous pouvons visualiser l'estimation de sa densité et la trace de toutes les sorties issues de l'échantillonnage. 

Voici l'estimation de quelques variables. Les graphiques de gauche montre la trace des valeurs prises par la chaîne à chaque itération. Nous observons que la chaîne mélange bien et se déplace bien dans la loi a posteriori sans être coincé à une partie de la chaîne. Cela explique que le modèle a bien convergé. 

Les graphiques de droite montre la densité. Nous pouvons comprendre quelles valeurs chaque paramètre peut prendre.

```{r, echo = F, fig.width = 12, fig.height = 13}
plot(reg[,2:5])
```

Avec le diagnostique de raftery, nous remarquons il nous faut à peu près 3.900 itérations. Nous avons fait 10.000 itérations qui est un nombre largement suffisant.

```{r, echo = F}
raftery.diag(reg)
```

## Choix de covariables

**Meilleur Modèle Bayésien**

Avec la fonction BMS, qui simule toutes les combinaisons possibles de modèle  par MCMC, nous pouvons obtenir les meilleurs modèles bayesiens. Ici, nous allons garder l'information de 500 meilleurs modèles.

```{r, message = F, echo = F}
train_encodded = dummy_cols(train, select_columns = "Matiere")
train_encodded = subset(train_encodded, select = -Matiere)
test_encodded = dummy_cols(test, select_columns = "Matiere")
test_encodded = subset(test_encodded, select = -Matiere)
```

```{r, echo = F, include = F, message = F, warning = F}
reg_2 = bms(train_encodded)
```

Voici les 5 meilleures modèles obtenus. Les variables ayant le coefficiet 1 sont les variables prises par chaque modèle. Le meilleur modèle prend que la matière *allemand* comme la variable explicative. Le deuxième meilleur modèle ne considère aucune variable comme significative. Dans le reste, les modèles prennent deux covariables incluant l'*allemand*. La matière *allemend* semble avoir un impact.

Nous remarquons également que les meilleurs modèles prennent moins de covariables, 1 ou 2, voire 0

```{r, echo = F}
options(width = 100)
topmodels.bma(reg_2)[,1:5]
```

# 3. Analyse Fréquentiste

Nous pouvons maintenant effectuer l'analyse fréquentiste pour la comparaison. Le modèle linéaire fréquentiste reprend les mêmes covariables significatives que le premier modèle bayésien, c'est à dire *anglais*, *doc lycées*, *éducation*, *histo & géo*, *lettres classiques*, *math & science & physique*, *maths*, *physique & chimie*, et *économie sociale*. Le modèle considère en plus *eps* et *svt* comme significatives.

```{r, echo = F}
reg_freq = lm(Barre ~ ., data = train)
summary(reg_freq)
```
En terme de AIC, le meilleur modèle fréquentiste propose encore plus de covariables, avec le *taux d'accès attendu du premier* en plus.

```{r, echo = F}
reg_freq2 = step(lm(Barre ~ ., data = train), trace = 0)
summary(reg_freq2)
```

# 4. Prédiction

Nous pouvos comparer la prédiction du modèle bayésien et du modèle fréquentiste sur les observations de test qui correspondent à 10% de notre jeu de données.

Sur les deux graphiques, les points gris correspondent aux vraies observations.

Dans la prédiction fréquentiste, nous remarquons qu'il y a une grande partie d'observations qui n'est pas dans l'intervalle de confiance prédit. L'incertitude n'est pas assez forte dans le cadre fréquentiste.

Dans la prédiction bayésienne, presque toutes les observations sont dans l'intervalle de crédibilité prédit par le modèle. L'incertitude est beaucoup plus large.

```{r, echo = F, include = F}
pred_reg = pred.density(reg_2, test_encodded)
pred_freq = predict(reg_freq2, test, se.fit = T)
```

```{r, echo = F, fig.align='center', fig.width=10, fig.height = 3.5}
freq = ggplot(test, aes(Barre, Barre))+
  geom_point(color = 'gray')+
  geom_abline(slope = 1, intercept = 0, color = 'gray', alpha = 0.7)+
  geom_point(aes(test$Barre, pred_freq$fit), color = 'darkgoldenrod2')+
  geom_errorbar(aes(ymin = (pred_freq$fit - pred_freq$se.fit), ymax = (pred_freq$fit + pred_freq$se.fit)), width = 0.1, color = 'darkgoldenrod2')+
  theme_minimal()+
  ggtitle("Prédiction Fréquentiste")+
  theme(plot.title = element_text(size = 11, hjust = 0.5))

bayes = ggplot(test, aes(Barre, Barre))+
  geom_point(color = 'gray', alpha = 0.7)+
  geom_abline(slope = 1, intercept = 0, color = 'gray', alpha = 0.7)+
  geom_errorbar(aes(ymin = quantile(pred_reg, .025), ymax =quantile(pred_reg, .975)), width = 0.1, color = 'darkgoldenrod2', lty = 2)+
  theme_minimal()+
  ggtitle("Prédiction Bayésienne")+
  theme(plot.title = element_text(size = 11, hjust = 0.5))

grid.arrange(freq, bayes, ncol = 2, top=textGrob("Fréquentiste vs. Bayésienne"))
```

# 5. Mathématiques & Anglais

Maintenant, nous allons nous concentrer uniquement sur la mutation en mathématiques, puis sur la mutation en anglais.

## Mutation en mathématiques

**Approche Bayésienne**

Nous allons effectuer la régression bayésienne avec 10.000 itérations que sur les observations concernant les mathématiques. Donc ici, la variable matière n'est plus incluse dans les covariables.

```{r, echo = F}
mutation_math = mutation_gen[mutation_gen$Matiere == "MATHS", ]
mutation_math = subset(mutation, select = -c(code_etablissement, ville, etablissement, commune, Matiere))

set.seed(56)
split = sample(2, nrow(mutation_math), replace = T, prob = c(0.9, 0.1))
train_math = mutation_math[split == 1, ]
test_math = mutation_math[split == 2, ]
```

Le modèle nous donne deux variables significatives : Le *taux de réussite attendu de série L* et le *taux d'accès brut de première*.

```{r, echo = F}
reg_math = MCMCregress(Barre ~ ., data = train_math)
print(summary(reg_math)[2], digits = 2)
```

Avec les graphqiues, nous pouvons remarquer que le modèle a bien convergé.

```{r, fig.height = 4, fig.width = 12, echo = F}
plot(reg_math[,3])
```

```{r, fig.height = 4, fig.width = 12, echo = F}
plot(reg_math[,4])
```

Les 5 meilleures modèles obtenus avec la fonction BMS, nous avons deux modèles qui prennent chacun l'une des deux variables données par le modèle précédant. 

```{r, echo = F, include =F}
reg_math_2 = bms(X.data = train_math)
```

```{r, echo = F}
topmodels.bma(reg_math_2)[,1:5]
```

**Approche fréquentiste**

Avec l'analyse fréquentiste, les variables significatives sont le *taux de réussite attendu de série L*, le *taux d'accès brut de seconde*, et le *taux d'accès brut de première*.

Le modèle fréquentiste garde toujours plus de covariables que les modèles bayésiens, incluant celles données par les modèles bayésiens.

```{r, echo = F}
reg_freq_math = lm(Barre ~ ., data = train_math)
summary(reg_freq_math)
```

Le meilleur modèle en terme de AIC propose exactement les même covariables que le modèle bayésien, proposant le *taux de réussite attendu de série L* et le *taux d'accès brut de première*.

```{r, echo = F}
reg_freq_math2 = step(lm(Barre ~ ., data = train_math), trace = 0)
summary(reg_freq_math2)
```

**Prédiction**

Nous pouvons comparer la prédiction qui combine les meilleurs modèles bayésien et celle du modèle fréquentiste.

Le modèle fréquentiste surestime dans la plupart du temps et il y a peu d'observations qui sont incluses dans l'intervalle de confiance. 
Quant au modèle bayésien, l'incertitude est très forte. Nous avons tous les observations qui se trouvent dans l'intervalle de crédibilité du modèle.

```{r, echo = F, fig.align='center', fig.width=10, fig.height=3.5}
pred_reg_math = pred.density(reg_math_2, test_math)
pred_freq_math = predict(reg_freq_math2, test_math, se.fit = T)

freq_math = ggplot(test_math, aes(Barre, Barre))+
  geom_point(color = 'gray', alpha = 0.7, size = 1)+
  geom_abline(slope = 1, intercept = 0, color = 'gray')+
  geom_point(aes(test_math$Barre, pred_freq_math$fit), color = 'darkgoldenrod2')+
  geom_errorbar(aes(ymin = (pred_freq_math$fit - pred_freq_math$se.fit), ymax = (pred_freq_math$fit + pred_freq_math$se.fit)), width = 0.1, color = 'darkgoldenrod2')+
  theme_minimal()+
  ggtitle("Prédiction Fréquentiste")+
  theme(plot.title = element_text(size = 11, hjust = 0.5))

bayes_math = ggplot(test_math, aes(Barre, Barre))+
  geom_point(color = 'gray', alpha = 0.7, size=1)+
  geom_abline(slope = 1, intercept = 0, color = 'gray')+
  geom_errorbar(aes(ymin = quantile(pred_reg_math, .025), ymax =quantile(pred_reg_math, .975)), width = 0.1, color = "darkgoldenrod2", lty = 2)+
  theme_minimal()+
  ggtitle("Prédiction Bayésienne")+
  theme(plot.title = element_text(size = 11, hjust = 0.5))

grid.arrange(freq_math, bayes_math, ncol = 2, top=textGrob("Fréquentiste vs. Bayésienne"))
```


## Mutation en anglais

```{r, echo = F}
mutation_en = mutation[mutation$Matiere == "ANGLAIS", ]
mutation_en = subset(mutation_en, select = -c(code_etablissement, ville, etablissement, commune, Matiere))

set.seed(2023)
split = sample(2, nrow(mutation_en), replace = T, prob = c(0.8, 0.2))
train_en = mutation_en[split == 1, ]
test_en = mutation_en[split == 2, ]
```


**Approche Bayésienne**

Nous allons également effectuer la régression bayésienne avec 10.000 itérations uniquement sur les observations concernant l'anglais. Nous obtenons qu'une seule variable significative : le *taux d'accès brut de première*.

```{r, echo = F}
reg_en = MCMCregress(Barre ~ ., data = train_en)
print(summary(reg_en)[2], digits = 2)
```

Avec les graphique, nous pouvons remarquer que le modèle a bien convergé.

```{r, echo = F, fig.height = 8, fig.width = 12}
plot(reg_en[,3:4])
```

Les meilleurs modèles BMS incluent différentes variables telles que l'*effectuf de première*, le *taux de réussite attendu de série L*, et le *taux brut de réussite de série ES*.

```{r, echo = F, include =F}
reg_en_2 = bms(X.data = train_en)
```

```{r, echo = F}
topmodels.bma(reg_en_2)[,1:5]
```

\newpage
Avec l'approche fréquentiste, le résultat est en accord avec le première modèle bayésien, en gardant le *taux d'accès brut de première* comme la variable significative unique.

```{r, echo = F}
reg_freq_en = lm(Barre ~ ., data = train_en)
summary(reg_freq_en)
```

Néanmins, 5 variables sont considérés commes significatives dans le meilleur modèle AIC : le *taux brut de réussite de série ES*, le *taux de réussite attendu de série L*, le *taux de réussite attendu de série S*, et le *taux d'accès brut de première*

```{r, echo = F}
reg_freq_en2 = step(lm(Barre ~ ., data = train_en), trace = 0)
summary(reg_freq_en2)
```

**Prédiction**

Dans la prédiction, le modèle fréquentiste surestime toujours dans la plupart du temps et il y a peu d'observations qui se trouvent dans l'intervalle de confiance. Dans le cas bayésien, l'incertitude est toujours très forte. Nous avons tous les observations qui se trouvent dans l'intervalle de crédibilité du modèle.

```{r, echo = F, fig.align='center', fig.width=10, fig.height=4}
pred_reg_en = pred.density(reg_en_2, test_en)
pred_freq_en = predict(reg_freq_en2, test_en, se.fit = T)

freq_en = ggplot(test_en, aes(Barre, Barre))+
  geom_point(color = 'gray', alpha = 0.7, size =1)+
  geom_abline(slope = 1, intercept = 0, color = 'gray')+
  geom_point(aes(test_en$Barre, pred_freq_en$fit), color = 'darkgoldenrod2')+
  geom_errorbar(aes(ymin = (pred_freq_en$fit - pred_freq_en$se.fit), ymax = (pred_freq_en$fit + pred_freq_en$se.fit)), width = 0.1, color = 'darkgoldenrod2')+
  theme_minimal()+
  ggtitle("Prédiction Fréquentiste")+
  theme(plot.title = element_text(size = 11, hjust = 0.5))

bayes_en = ggplot(test_en, aes(Barre, Barre))+
  geom_point(color = 'gray', alpha = 0.7, size=1)+
  geom_abline(slope = 1, intercept = 0, color = 'gray')+
  geom_errorbar(aes(ymin = quantile(pred_reg_en, .025), ymax =quantile(pred_reg_en, .975)), width = 0.1, color = "darkgoldenrod2", lty = 2)+
  theme_minimal()+
  ggtitle("Prédiction Bayésienne")+
  theme(plot.title = element_text(size = 11, hjust = 0.5))

grid.arrange(freq_en, bayes_en, ncol = 2, top=textGrob("Fréquentiste vs. Bayésienne"))
```

Pour les mutations en mathématiques en anglais, les covariables significatives sont différentes. Les covariables n'agissent pas de la même manière dans les deux disciplines.

# 6. Conclusion

Dans notre étude, nous retrouvons les covariables similaires dans les approches bayésiens et fréquentistes. Néanmoins lorsque nous avons beaucoup de variables, le modèle fréquentiste a tendance à garder plus de variables que le modèle bayésien. 

L'incertitude est plus large dans le cas bayésien qui inclut la grande partie des vraies valeurs observées dans son intervalle de crédibilité. L'écart entre les vraies valeurs et la prédiction du modèle fréquentiste reste grande par rapport au modèle bayésien.
