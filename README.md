# statistics_big_data_dauphine

<br/>
This repository is about projects that I have completed during my course of Statistics and Big Data at Dauphine. <br/><br/>
Tools : R, Python, SQL <br/><br/>
Skills : 
Probability, Descriptive Statistics, Inferential Statistics, Gaussian Linear Model
Generalized Linear Model, Model Selection, Non-parametric Estimation, Time Series, Bayesian Estimation, Extreme Values, PCA, FCA, Classification, Missing Values, Survival Model <br/>
<br/>

----------


**PREDICTIVE MODELS**<br/>



- **[R] Gaussian Linear Model**<br/>
Project : [click here](https://github.com/haejiyun/statistics-big-data/blob/main/Gaussian%20Linear%20Model/modele_lineaire_gaussien_haeji_yun.pdf)<br/>
Application of Gaussian Linear Model for the prediction of maize varieties based on its characteristics. Descriptive analysis, logical covariate selection, and statsitical tests are applied in order to verify if the gaussian linear model is right model to use.
<br/>

- **[R] Generalized Linear Model & Model Selection**<br/>
Project : [click here](https://github.com/haejiyun/statistics-big-data/blob/main/Generalized%20Linear%20Model/MLG_haeji_yun.pdf)<br/>
Rain prediction at Bale in Switzerland based on past meteorological information. The dataset has 1,180 observations and 46 covariates which are very correlated. The first part of the project is about selecting the relevant covariates and the second part of the project is about creating an efficient binary model.
<br/>

- **[R] Non Parametric Estimation**<br/>
Project : [click here](https://github.com/haejiyun/statistics-big-data/blob/main/Non%20Parametric%20Estimation/Estimation_non_parametrique.pdf)<br/>
Theoretical application of non parametric model focusing on explanation of its mathematical foundation from kernel estimation to non parametric regression. The emphasis on the choice of the window and the cross-validation.
<br/>

- **[R] Principal Component Analysis, Factorial Correspondance Analysis, CAH**<br/>
PAC Project : [click here](https://github.com/haejiyun/statistics-big-data/blob/main/Scoring/ACP_haeji_yun.pdf)<br/>
Analysis of daily protein consumption of european countries. The dataset is composed of different proteine source with the protein quantity of 25 countries based on which similarities, differences, and particularities are analysed.<br/>
FCA & AHC Project : [click here](https://github.com/haejiyun/statistics-big-data/blob/main/Scoring/AFC_Classification_haeji_yun.pdf)<br/>
Analysis of 2017 presidential election of France. 14 candidats and the number of votes they received in different departments compose the dataset. The study gives the first insight on the association between the candidates and the departments. The study is then deepen with the clustering method.
<br/>

- **[R] Time Series**<br/>
Project : [click here](https://github.com/haejiyun/statistics-big-data/blob/main/Time%20Series/time_series_haeji_yun.pdf)<br/>
Application of time series theory on anlysis of kilo coffee price. The analysis is done with graphical method and different time series analysis methods in order to make a prediction of future kilo coffe prices. Differents time series models are compared.
<br/>

- **[R] Bayesian Estimation**<br/>
Project : [click here](https://github.com/haejiyun/statistics_big_data_dauphine/blob/main/Statistique%20Bayesinne/statistique_bayesienne.pdf)<br/>
Prediction of necessary points in order for a high school teacher to get mutated to other school. The number of points is prediction for each set of 'high school - subject' using baysian regression. A comparison with a frequentist approch is tested in order to check the plausibility of the bayesian model.  
<br/>

- **[R] Extreme Values**<br/>
Project : [click here](https://github.com/haejiyun/statistics_big_data_dauphine/blob/main/Valeurs%20ExtrÃªmes/valeurs_extremes_haeji_yun.pdf)<br/>
Extreme values prediction for daily precipitaion at Marseille. An extrapolation on 1000 years is made from a dataset containing observations of 127 years. Different extreme values models are tested in order to find the most relevant one. 
<br/>

- **[Python] Survival Model**<br/>
Project : [soon]()<br/>
Churn analysis of an online game. Considering 90 days of inactivity as churn, the probability to churn is predicted based on the users' game characteristics such as the level, the race of game character, the zone visited by the character, belonging to a group etc.
<br/>



**MACHINE LEARNING**<br/>


**DEEP LEARNING**<br/>
