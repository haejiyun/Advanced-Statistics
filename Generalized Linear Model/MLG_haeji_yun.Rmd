---
title: "Choix de Modèles & Modèles Linéaires Généralisés"
author: "Haeji Yun"
date: "2023-06-29"
output: pdf_document
---

Dans cette analyse, nous nous intéressons à prédire s'il va pleuvoir ou pas le lendemain à Bâle en nous basant sur différentes variables météorologiques qui composent notre jeu de données. 

Notre jeu de données contient 1180 observations et 46 variables. Les observations correspondent aux différents jours entre 2010 et 2018 et les variables correspondent à différentes caractéristiques météorologiques.

# Chargement de données

Notre variable d'intérête est la variable qualitative *pluie.demain* qui est un boléen indiquant s'il a plu le lendemain ou pas. La valeur est *True* s'il a plu le lendemain et *False* dans le cas contraire.

Les autres 45 variables sont quantitatives qui vont nous servir à expliquer la variable cible. Elles sont composées de :

- Les variables de temps telles que l'année, le mois, le jour, l'heure et la minute

- La moyenne, la minimale et la maximale de différentes caractéristiques météorologiques telles que la température, l'humidité, la pression, la nébulosité en pourcentage, la nébulosité forte, la nébulosité moyenne, la nebulosité faible, la vitésse du vent à 10 m, la vitesse du vent à 80 m, la vitesse du vent à 900 m, la rafale

- La moyenne de la direction de vent à 10 m, la direction de vent à 80 m, et la direction de vent à 900 m

- Les valeurs totales de précipitations, de néige, d'ensoleilement, de rayonnement solaire

Dans nos variables, nous avons à la fois les mêmes variables mesurées sur de niveaux différentes telles que la nébulosité d'intensité différente et le vent à altitudes différentes, et les mêmes variables représentées par des mesures différentes telles que la moyenne, la minimale et la maximale. Nous pouvons déjà supposer qu'il y aura beaucoup de variables qui sont corrélées entre elles.

Le fichier csv qui contient notre jeu de données est téléchargé sous forme d'un dataframe. Nous allons nous contenter d'afficher la dimension, la liste et le type de variables de notre jeu de données car il est difficile d'avoir toutes les colonnes en dataframe sur une page à cause de nombre élevé de variables. 


```{r, echo = F}
meteo_train = read.table('meteo.train.csv', sep = ',', header = T, row.names = 1)
str(meteo_train)
```

# Etude Exploratoire

## Valeurs manquantes et valeurs uniques

Nous n'avons pas de données manquantes dans notre jeu de données.

```{r}
sum(is.na(meteo_train))
```

Néanmoins, nous observons que la variables *Hour* et *Minute* ont une valeur unique *0* pour toutes les observations. Ces deux variables ne sont donc pas informatives et ne donnent aucune explication sur notre variable cible. Nous pouvons déjà supprimer les deux.

```{r, echo = F}
summary(meteo_train[,4:5])
```

Nous retrouvons avec un jeu de données avec 1180 observations et 44 variables au lieu de 46.

```{r, echo = F}
meteo_train = subset(meteo_train, select = -c(Hour,Minute))
dim(meteo_train)
```

## Variable cible

Notre variable d'intérêt *pluie.demain* a 49% de valeur *True* et 51% de valeur *False*. 

Nous avons une quantité équivalente des deux classes. Cela nous évitera de réduire la performance de prédiction en apprenant mieux une classe avec plus de données disponibles par rapport à l'autre classe.

Nous pourrons également diviser les données d'entraînement et de test de façon aléatoire par la suite.


```{r, echo = F, fig.width = 4, fig.height = 3, fig.align = 'center'}
library(ggplot2)

ggplot(meteo_train, aes(pluie.demain))+
  geom_bar(fill = c('darkorange2','darkolivegreen4'))+
  theme_minimal()+
  theme(plot.title = element_text(hjust = 0.5))+
  ylab("Nombre de jours")+
  xlab("Pluie")+
  ggtitle("Distribution de Variable Cible")
```

## Variables explicatives

Nous pouvons étudier la corrélation de variables avec une matrice de corrélation.

Comme attendue, nous observons des corrélations sur des blocs de variables : 

- Entre les différents niveaux de même variable : la nébulosité d'intensité différente et le vent à altitudes différents

- Entre les différentes mesures de même variable : la moyenne, la minimale et la maximale de la température, de l'humidité et de la pression

- Entre les différents variables : la vitesse de vent, la direction de vent et la rafale.

```{r, echo = F, message = F, fig.width = 12, fig.height = 10}
library(corrplot)
corrplot(cor(meteo_train, use="complete"), tl.cex = 0.8, tl.col = "gray35")
```

# Sélection de variables

Comme notre étude consiste à prédire s'il va pleuvoir le lendemain ou pas, c'est une variable discrète binaire *vrai* ou *faux* que nous voudrons obtenir. Il s'agit d'une classification.

Nous allons donc utiliser la régression logistique qui estime pour chaque observation la probabilité qu'un événement se produise, que nous pouvons utiliser pour classifier selon le seuil de probabilité que nous fixons.

Parmi les critères de sélection de modèles, nous ne pourrons pas utiliser R2 ajusté et Cp de Mallows car ils utilisent le résidu de modèle linéaire. Nous allons utiliser les critères *aic* et *bic* qui utilisent la vraisemblance.

Les steps *both*, *forward*, et *backward* de *aic* et de *bic* ont donné à peu près les mêmes résultats. Pour cela, nous avons opté de garder le step *forward* pour faciliter la compréhension de sélection effectuée.

Avec le step *forward*, l'initialisation est faite avec le modèle qui ne continet pas de variablie explicative. Nous calculons *aic* et *bic* du modèle. Puis la variable qui minimise *aic* ou *bic* est ajouté. Cet ajout de variable continue une par une jusqu'à ce que le modèle obtenu n'a plus de *aic* ou *bic* inférieur au modèle précédant.


```{r, include = F}
library(MASS)
zero_model = glm(pluie.demain ~ 1 , data = meteo_train, family = binomial)
full_model = glm(pluie.demain ~ . , data = meteo_train, family = binomial)

step_aic = stepAIC(zero_model, direction = 'forward', scope = list(lower = zero_model, upper = full_model))
step_bic = stepAIC(zero_model, direction = 'forward', scope = list(lower = zero_model, upper = full_model), k = log(nrow(meteo_train)))
```

Le meilleur modèle en terme de *bic* a gardé 8 variables et celui de *aic* a gardé 15 variables. 

Les modèles minimisent chacun son *bic* et son *aic*. Le *bic* est égale à 1347,73 avec 8 variables et le *aic* est égale à 1292,49 avec 15 variables.

```{r, echo = F, fig.width = 12, fig.height = 5, warning = F}
library(gridExtra)
library(grid())

aic = data.frame(value = step_aic$anova$AIC, index = c(1:15))
bic = data.frame(value = step_bic$anova$AIC, index = c(1:8))

bic_min = data.frame(min = min(bic$value), index = which.min(bic$value))
aic_min = data.frame(min = min(aic$value), index = which.min(aic$value))

plot_bic = ggplot(bic, aes(x=index, y = value))+
  geom_line(color = 'darkolivegreen4', size = 1)+
  geom_point(aes(x = bic_min$index, y = bic_min$min), color = 'darkorange', pch = 1, size = 3)+
  geom_text(aes(x = bic_min$index - 0.2, y = bic_min$min - 10), label = paste0("(",bic_min$index, ", ", round(bic_min$min,2),")"), size = 3, color = 'gray35')+
  theme_minimal()+
  ylab("BIC")+
  xlab("Nombre de variables")+
  ggtitle("BIC")+
  theme(plot.title = element_text(hjust = 0.5))

plot_aic = ggplot(aic, aes(x=index, y = value))+
  geom_line(color = 'darkolivegreen4', size = 1)+
  geom_point(aes(x = aic_min$index, y = aic_min$min), color = 'darkorange', pch = 1, size = 3)+
  geom_text(aes(x = aic_min$index - 0.5, y = aic_min$min - 11), label = paste0("(",aic_min$index, ", ", round(aic_min$min,2),")"), size = 3, color = 'gray35')+
  theme_minimal()+
  ylab("AIC")+
  xlab("Nombre de variables")+
  ggtitle("AIC")+
  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(plot_bic, plot_aic, ncol = 2, top=textGrob("Variables sélectionnées"))
```

Les 15 variables sélectionnées par *aic* sont affichées ci-dessous. Nous observons les variables ayant des corrélations detectées précedemment entre:

- les nébulosités d'intensité différente

- la vitesse de vent, la direction de vent et la rafale

- la température minimale et la température maximale


```{r, echo = F}
variable_aic = rownames(data.frame(step_aic$coefficients))
variable_aic
```

Le *bic* a retenu beaucoup moins de variables par rarpport à *aic*. Nous observons quand même les variables ayant des corrélations détectées précedemment entre : 

- la température minimale et la température maximale

- la nébulosité moyenne et la nébulosité maximale

- La direction de vente et la rafale

```{r, echo = F}
variable_bic = rownames(data.frame(step_bic$coefficients))
variable_bic
```

Nous allons afficher la corrélation entre les variables retnues par *aic* et éliminer les variables corrélées en privilégiant les variables retenues par *bic* :

- Il y a une forte corrélation entre la rafale maximale avec la vitesse minimale à 10 m d'altitude, la vitesse maximale à 10 m d'altitude, et la vitesse moyenne à 80 m d'altitude. Aucune des 4 variables a été retenue par *bic*. Nous allons garder seulement la rafale maximale. Comme elle est la plus fortement corrélée avec les trois autres variables, elle expliquerait bien les variabilités expliquées par ces trois variables après leur élimination.

- Une autre forte corrélation est présente entre la direction moyenne de vent à 80 m d'altitude et la direction moyenne de vent à 900 m d'altitude. Nous allons garder celle à l'altitude 900 m car elle est retenue par *bic* alors que celle à l'altitude 80 m n'est pas rentenue par *bic*.

- Nous avons également une forte corrélation etnre la température minimale et la température maximale. Néanmoins les deux variables sont retenues par *bic*. Nous allons garder la température maximale car l'entraînement par la régression logistique considère qu'elle seule est significative.


```{r, echo = F, message = F, fig.width = 12, fig.height = 10}
selection_aic = meteo_train[c(variable_aic[2:15],"pluie.demain" )]
selection_bic = meteo_train[c(variable_bic[2:8],"pluie.demain" )]

corrplot(cor(selection_aic, use="complete"), tl.cex = 0.8, tl.col = "gray35", type="upper")
```

En éliminant les 5 variables corrélées, nous n'avons plus de problème de corrélations. Nous nous retrouvons avec 10 variables qui sont :

- La nébulosité maximale
- La nébulosité minimale
- La nébulosité moyenne
- La pression minimale
- La rafale
- La température maximale
- La direction moyenne de vent à l'altitude de 900 m
- L'année
- La quantité totale de negie
- Le booléen indiquant s'il a plu le lendemain ou pas

Ce sera notre jeu de données final pour trouver un modèle de prédiction.


```{r, echo = F, fig.width = 12, fig.height = 10}
selection_final = subset(selection_aic, 
                         select = -c(Wind.Speed.daily.max..10.m.above.gnd., Wind.Speed.daily.min..10.m.above.gnd., Temperature.daily.min..2.m.above.gnd.,
                                     Wind.Direction.daily.mean..80.m.above.gnd., Wind.Speed.daily.mean..80.m.above.gnd.))
corrplot(cor(selection_final, use="complete"), tl.cex = 0.8, tl.col = "gray35", type="upper")
```

\newpage
# Régression Logistique

Nous pouvons effectuer la régression logistique avec les 10 variables que nous avons rentenu.


## Séparation de données

Pour cela, nous allons séparer le jeu de données en set d'entraînement et set de test afin de pouvoir évaluer et valider la performance du modèle.

Le set d'entrainement sert à entraîner le modèle. Le modèle apprends du set en estimant les coefficients qui définissent la relation entre la variable cible et les variables explicatives. 

Le set de test sert à évaluer la performance du modèle. Seules avec les variables explicatives, nous utilisons le modèle pour prédire la variable d'intérêt et comparons avec les vraies valeurs.

L'entraînement sur le set d'entraînement et l'évaluation de performance sur le set de test nous permettrait d'estimer à quel point le modèle est performant sur les données non observées.

Les deux classes de notre variable cible sont bien équilibrées. Nous pouvons donc séparer les données de façon aléatoire. 80% de nos données seront gardées pour l'entraînement et 20% pour le test.


```{r}
set.seed(1)
split = sample(2, nrow(selection_final), replace = T, prob = c(0.8, 0.2))
train = selection_final[split == 1, ]
test = selection_final[split == 2, ]
```


## Modèle 1

Dans un premier temp, nous pouvons entraîner en gardant tous les 10 covariables du set d'entraînement. Il y a quatre variables, *la nébulosité maximale*, *la pression minimale*, *la rafale*, et *la température maximale* qui sont detectés significatives.

```{r, echo = F}
model_1 = glm(data = train, pluie.demain ~ ., family = binomial)
summary(model_1)
```
## Modèle 2

Nous pouvons créer un deuxième modèle en gardant les 4 covariables detectées comme significatives dans le modèle 1. Ce modèle detecte tous les covariables comme significatives. Nous pouvons sélectionner ce modèle. 

Nous avons des coefficients positifs pour la nébulosité maximale, la température maximale et la direction moyenne de vent. La probabilité de pleuvoir le lendemain augmente avec l'augmentation de l'un des ces trois variables. 

Nous avons un coefficient négatif pour la pression minimale. La probabilité de pleuvoir le lendemain diminue avec l'augmentation de pression.


```{r, echo = F}
model_2 = glm(data = train, pluie.demain ~ .-Total.Cloud.Cover.daily.mean..sfc. -Year -Wind.Gust.daily.max..sfc.
              -Snowfall.amount.raw.daily.sum..sfc. -Total.Cloud.Cover.daily.min..sfc., family = binomial)
summary(model_2)
```
## Modèle 3

Nous pouvons également créer un troisième modèle en appliquant la fonction *step* qui nous donne un modèle avec une combinaison de covariables qui minimise *aic* 

Le modèle sélectionné contient 6 variables qui sont toutes significatives.

Nous avons des coefficients positifs pour la nébulosité moyenne maximale, la rafale maximale, la température maximale, la directin moyenne de vent, et la nébulosité totale minimale. La probabilité de pleuvoir le lendemain augmente avec l'augmentation de l'un des ces trois variables. 

Nous avons un coefficient négatif pour la pression minimale. La probabilité de pleuvroir le lendemain diminue avec l'augmentation de pression.


```{r, echo = F}
model_3 = step(model_1, trace = F)
summary(model_3)
```


# Évaluation de modèle

Nous allons maintenant évaluer le modèle 2 et le modèle 3 qui ont gardé que des covariables significatives en faisant la prédiction sur le set de test. 

Pour commencer, nous allons fixé le seuil à 50%. Tous les observations ayant une probabilité de pleuvoir le lendemain supérieur à 0,5 auront la valeur *True* et le reste la valeur *False*.

```{r, echo = F}
pred_train_2 = predict(model_2, train, type = 'response')
pred_train_3 = predict(model_3, train, type = 'response')

pred_test_2 = predict(model_2, test, type = 'response')
pred_test_3 = predict(model_3, test, type = 'response')

pred_2 = pred_test_2 > 0.5
pred_3 = pred_test_2 > 0.5
```

## Précision

La précision est une métrique basée sur la matrice de confusion pour évaluer la performance de modèle de classification. Elle correspond à la proportion de bonne prédiction sur la prédiction totale.

Le modèle 2 a une précision de 73%.

```{r, echo = F}
mean(pred_2 == (test$pluie.demain == T))
table(pred_2, test$pluie.demain)
```

Le modèle 3 a également une précision de 73%. 

```{r, echo = F}
mean(pred_3 == (test$pluie.demain == T))
table(pred_3, test$pluie.demain)
```

Dans notre cas, la valeur positive semble mieux predire correctement que la valeur négative mais la différence entre les deux classes n'est pas alertant.

## ROC

Une optimisation du taux de vrai positif et du taux de faux positif à l'aide de la courbe ROC nous permettra d'avoir un modèle performant. La courbe ROC représente le taux de vrai positif en fonction du taux de faux positif. 

Nous cherchons un seuil qui maximise le taux de vrai positif et minimise le taux de faux positif. Notre courbe ROC est symétrique avant et après le seuil 0,5.

0,5 est le bon seuil pour notre modèle.

```{r, warning = F, echo = F, fig.width = 12, fig.height = 5}
library(plotROC)

p_train_rocr2 = data.frame(prediction = pred_train_2, real = train$pluie.demain, data_name = "train2")
p_train_rocr3 = data.frame(prediction = pred_train_3, real = train$pluie.demain, data_name = "train3")

p_test_rocr2 = data.frame(prediction = pred_test_2, real = test$pluie.demain, data_name = "test2")
p_test_rocr3 = data.frame(prediction = pred_test_2, real = test$pluie.demain, data_name = "test3")

p_rocr2 = rbind(p_train_rocr2, p_test_rocr2)
p_rocr3 = rbind(p_train_rocr3, p_test_rocr3)

rocr2 = ggplot(p_rocr2, aes(d = real, m = prediction, color = data_name))+
  geom_roc(size = 0.8)+
  geom_abline(intercept = 0, slope = 1, linetype = 3)+
  geom_abline(intercept = 1, slope = -1, alpha = 0.1)+
  theme_minimal()

rocr3 = ggplot(p_rocr3, aes(d = real, m = prediction, color = data_name))+
  geom_roc(size = 0.8)+
  geom_abline(intercept = 0, slope = 1, linetype = 3)+
  geom_abline(intercept = 1, slope = -1, alpha = 0.1)+
  theme_minimal()

grid.arrange(rocr2, rocr3, ncol = 2, top=textGrob(""))
```

## AUC

Nous pouvons également regarder l'AUC, laire sous la courbe ROC. Elle représente le degré de séparabilité. Elle nous dit à quel point le modèle distingue entre les différentes classes. 

L'AUC est en général compris entre 0,5 et 1. où 0,5 est égale à un modèle aléatoire et 1 est égale au modèle parfait qui prédit parfaitement toutes les observations

Pour le modèle 2, nous avons une AUC de 0,77 pour le set test et 0,79 pour le set train.

```{r, warning = F}
calc_auc(rocr2)
```

Pour le modèle 3, nous avons une AUC de 0,77 pour le set test et 0,80 pour le set train. 

```{r, warning = F}
calc_auc(rocr3)
```

Les deux modèles ont des performances très correctes. Le modèle 3 ajuste légèrement mieux mais tous les deux modèles généralisent aussi bien sur le set test. Nous allons donc garder le modèle 3.



# Prédiction

Avec notre modèle retenu, nous pouvons faire la prédiction avec un seuil de 0,5 sur le jeu de données à prédire fourni.

Au final, 55% de jours est prédit pluvieux le lendemain et 45% de jours le contraire parmi les 290 jours.

```{r, echo = F, fig.width = 4, fig.height = 3, fig.align = 'center'}
meteo_test = read.table('meteo.test.csv', sep = ',', header = T, row.names = 1)

final_predict = predict(model_3, meteo_test, type = 'response')
prediction_test = final_predict > 0.5

pred = data.frame(prediction_test)

ggplot(pred, aes(prediction_test))+
  geom_bar(fill = c('darkorange2','darkolivegreen4'))+
  theme_minimal()+
  theme(plot.title = element_text(hjust = 0.5))+
  ylab("Nombre de jours")+
  xlab("Pluie")+
  ggtitle("Prévision de Pluie")
```


```{r, echo = F}
write.csv(prediction_test, file = "/Users/haeji/Desktop/prediction_test.csv")
```

```{r, include = F}
library(knitr)
purl("MLG_haeji_yun.Rmd")
```

